# -*- coding: utf-8 -*-
"""LVADSUSR170Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X7xjPSbT12OimMmx2BnqqXnEkeFK2O_f
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report,f1_score
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE

df = pd.read_csv("/content/winequality-red.csv")

df.info()

df.describe()

df.head()

df.shape

df.isna().sum()

columns_null=['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide',
              'sulphates']
for i in columns_null:
  plt.hist(df[i])
  plt.title(f"histogram of {i}")
  plt.ylabel('Frequency')
  plt.xlabel(i)
  plt.show()

columns_null=['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide',
              'sulphates']
for i in columns_null:
  df[i].fillna(df[i].mean(),inplace=True)

df.duplicated().sum()

df.drop_duplicates(inplace=True)

df.head()

# Remove outliers using IQR method
Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1
outliers = ((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)
df = df[~outliers]

# Map the 'quality' feature into two classes
def variable_change(quality):
    if quality >= 3 and quality <= 6:
        return 0
    elif quality >= 7 and quality <= 8:
        return 1
    else:
        return None

df['quality'] = df['quality'].apply(variable_change)

# Check the distribution of wine quality
print("Wine quality distribution:")
print(df['quality'].value_counts())

# Visualise the distribution of wine quality
plt.figure(figsize=(8, 6))
sns.countplot(x='quality', data=df, palette='viridis')
plt.title('Wine Quality Distribution')
plt.xlabel('Quality')
plt.ylabel('Count')
plt.xticks(rotation=0)
plt.show()

# Separate features and target variable
scaler=StandardScaler()
X = df.drop(columns=['quality'])
y = df['quality']

# Split the dataset into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Scaling the data
X_train=scaler.fit_transform(X_train)
X_test=scaler.transform(X_test)

# Apply SMOTE to handle class imbalance
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# Train a RF classifier
clf = RandomForestClassifier(random_state=42)
clf.fit(X_train_resampled, y_train_resampled)

# Predict on the test set
y_pred = clf.predict(X_test)

# Evaluate the RF model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1score = f1_score(y_test, y_pred)

print("Accuracy:", round(accuracy * 100, 2), "%")
print("Precision:", round(precision * 100, 2), "%")
print("Recall:", round(recall * 100, 2), "%")
print("F1-score", round(f1score * 100, 2), "%")

# Generate a classification report for RF
print("RF Classifier Metrics:")
print(classification_report(y_test, y_pred))

# Generate a confusion matrix for RF
conf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(5, 5))
sns.heatmap(conf_matrix, annot=True, cmap="viridis", fmt="d", cbar=False)
plt.title("Confusion Matrix for RF")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

